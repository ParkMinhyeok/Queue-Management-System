## 학습 데이터 셋 수집 및 학습
본 연구에서는 AlphaBot의 주행 성능 향상을 위해 반복적인 데이터셋 수집 및 모델 학습 과정을 수행하였다. 이 과정은 총 6단계로 진행되었으며, 각 단계별 데이터 수집 방식과 결과는 다음과 같다.

### 데이터셋 수집 및 학습 과정
1. 최초 학습
* 촬영 방식: AlphaBot이 정지된 상태에서 촬영
* 데이터셋 규모: 50개 이미지
* 결과: 직진 코스에서 안정적 주행 불가능

2. 직진 주행 데이터 보강
* 촬영 방식: 직진 주행 중 인식 실패 이미지 수집
* 데이터셋 규모: 총 150개 (기존 50개 + 신규 100개)
* 결과: 직진 주행 안정성 향상, 50cm 거리 간헐적 완주 가능
  
3. 코너 주행 데이터 추가
* 촬영 방식: 직진 주행 및 코너 부분 인식 실패 이미지 수집
* 데이터셋 규모: 총 200개 (기존 150개 + 신규 50개)
* 결과: 직진 코스 안정적 주행 가능, 코너 주행 불가능

4. 코너 주행 데이터 보강
* 촬영 방식: 코너 부분 인식 실패 이미지 중점 수집
* 데이터셋 규모: 총 292개 (기존 200개 + 신규 92개)
* 결과: 직진 및 코너 주행 안정화, 고속 코너 주행 시 어려움 발생

5. 대규모 코너 데이터 추가
* 촬영 방식: 코너 부분 인식 실패 이미지 대량 수집
* 데이터셋 규모: 총 631개 (기존 292개 + 신규 339개)
* 결과: 오히려 이전 단계보다 인식률 저하

6. 선별적 데이터 추가
* 촬영 방식: 코너 부분 인식 실패 이미지 선별 수집
* 데이터셋 규모: 총 353개 (4단계 292개 + 신규 61개)
* 결과: 5단계와 마찬가지로 인식률 저하 관찰

### 분석 및 고찰
데이터셋 구축 과정에서 관찰된 주요 특징은 다음과 같다:
1. 초기 정지 상태 이미지만으로는 실제 주행 상황 대응에 한계가 있었다.
2. 직진 및 코너 주행 데이터를 균형있게 추가함으로써 전반적인 주행 성능이 향상되었다.
3. 데이터셋의 양적 증가가 반드시 성능 향상으로 이어지지 않았으며, 오히려 과적합(overfitting) 문제가 발생할 수 있음을 확인하였다.
4. 최적의 성능은 4단계에서 관찰되었으며, 이는 292개의 균형잡힌 데이터셋으로 달성되었다.

## Video 1
실시간 감지되는 모습(on Server)
https://github.com/user-attachments/assets/791a788a-2774-4155-9b00-15ba741872b9

## Video 2
Video1의 전체 모습
https://github.com/user-attachments/assets/19642ecc-8298-46af-b4a0-1556da173d70
